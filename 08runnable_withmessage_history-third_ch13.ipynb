{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62394f61-a802-4671-a362-0a48a0f86f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20250816"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82327030-1d12-40f4-aa3d-02b8da5d5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://csp.gitbook.io/langchain-for-beginners/ch13-langchain-expression-language-lcel/08.-runnablewithmessagehistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf6cc50-27c1-4d43-bcd7-81cf44504c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 08. RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19282fc7-2b9c-4426-8629-5ef489bb41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d503e79e-24f6-41d2-b4e5-49b9755c89d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05a7cfcf-3501-40a9-b6e4-8087266f6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama3-70b-8192\")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant who is proficient in {ability}. Please respond in 20 characters or less.\",\n",
    "        ),\n",
    "        # Use conversation history as a variable, history becomes the key of MessageHistory\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),  # Use user input as a variable\n",
    "    ]\n",
    ")\n",
    "runnable = prompt | model  # Create a runnable object by connecting a prompt and a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a54b7ade-2a60-4865-8554-d53fe861ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf257bfd-1061-4c92-bd04-1bb9f52d6d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # A dictionary to store session records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23c77bd0-5ff5-49fe-86c0-dc9b3d2c38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve session records based on session ID\n",
    "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
    "    print(session_ids)\n",
    "    if session_ids not in store:  # If the session ID is not in the store\n",
    "        # Create a new ChatMessageHistory object and save it to the store.\n",
    "        store[session_ids] = ChatMessageHistory()\n",
    "    return store[session_ids]  # Returns the session record for the given session ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3018c43a-b156-4598-b635-60e584895d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = (\n",
    "    RunnableWithMessageHistory(  # RunnableWithMessageHistory Object creation\n",
    "        runnable,  # Runnable object to execute\n",
    "        get_session_history,  # Function to retrieve session records\n",
    "        input_messages_key=\"input\",  #Specifies the key to be processed with the latest input message\n",
    "        history_messages_key=\"history\",#Specifies the key to add the previous message.  \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e0998e-98cb-4483-9f1f-50bbfb9b089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if history_factory_config:\n",
    "        _config_specs = history_factory_config\n",
    "    else:\n",
    "        # If not provided, then we'll use the default session_id field\n",
    "        _config_specs = [\n",
    "            ConfigurableFieldSpec(\n",
    "                id=\"session_id\",\n",
    "                annotation=str,\n",
    "                name=\"Session ID\",\n",
    "                description=\"Unique identifier for a session.\",\n",
    "                default=\"\",\n",
    "                is_shared=True,\n",
    "            ),\n",
    "        ]\n",
    "except NameError:\n",
    "    # Fallback if history_factory_config isn't defined at all\n",
    "    _config_specs = [\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for a session.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e483d5cd-664f-4307-995c-65feecf01bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='adjacent side / hypotenuse', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 39, 'total_tokens': 47, 'completion_time': 0.02764438, 'prompt_time': 0.012345383, 'queue_time': 0.143315083, 'total_time': 0.039989763}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_bf16903a67', 'finish_reason': 'stop', 'logprobs': None}, id='run--202e0022-2f9d-457c-8175-dad34cafa22c-0', usage_metadata={'input_tokens': 39, 'output_tokens': 8, 'total_tokens': 47})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    # Pass the math related question \"What is the meaning of cosine?\" as input.\n",
    "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
    "    # Pass the session ID \"abc123\" as configuration information.\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc7623-2cb1-432e-9820-f83aeb9d466f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
